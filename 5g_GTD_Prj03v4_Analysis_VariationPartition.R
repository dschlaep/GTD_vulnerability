################### PARTITIONING OF VARIATION ##################
#
# Daniel Schlaepfer, 2015-2016
# 
# We calculated the uniquely attributable variation based on additive elements by Whittaker as percentage of the total variation for each variable for the extent of the study area for each climate condition. We partitioned the variation for the absolute variable values under each climate condition and as difference between future and current conditions. 
#	- requests 'get_precalculations' from '5a1_GTD_*.R'
#	- requests 'get_studyareaextents' from '5a1_GTD_*.R'

# Objective
#	- calculate variance/variation partitioning and/or variable importance among regions, shifts, GCMs, and RCPs
#	- consider cells that are in study area at least under one of the 33 climate conditions (12638 cells)
# 
# Insights
#	- Subject (here, cells) must be a factor (http://www.cookbook-r.com/Statistical_analysis/ANOVA/): "Also, for ANOVAs with a within-subjects variable, there must be an identifier column. In this case, it is subject. This identifier variable must be a factor. If it is a numeric type, the function will interpret it incorrectly and it won't work properly."
#	- Missing values: Crawley 2007, p. 472: "Notice that with just one missing value, each main effect appears in two tables (not one, as above). It is recommended that when there are missing values in a split-plot experiment you use lmer or lme instead of aov to fit the model."	
#
# Attempts
#	1) Variance partitioning based on sums of squares of an aov() fit
#		- Error(Cell/(RCP * GCM))
#		- subject = factor(cell)
#		- between-subject factors: region
#		- within-subject factors: RCP x GCM
#		- dat_anova1 = 20'020 cells x 32 (RCPs x GCMs)
#		 => aov-call kills R because of too high memory demand (>> 16 GB)
#		 => unbalanced design ==> use lme/lmer instead of aov
#
#	2) Variance partitioning based on sums of squares of an aov() fit
#		- Error(Cell/(RCP * GCM * shift))
#		- subject = factor(cell)
#		- between-subject factors: region
#		- within-subject factors: RCP x GCM x shift
#		- dat_anova2 = 20'020 cells x 32 (RCPs x GCMs) x 3 shifts
#		 ==> incorrect formulation: this creates cells x RCP x GCM x shift + region (with many empty 'cells') but it should be cells x RCP x GCM + region x shift
#
#	3) Variance partitioning based on sums of squares of an aov() fit
#		- Error(Cell/(shift * RCP * GCM))
#		- subject = factor(cell)
#		- between-subject factors: region x shift
#		- within-subject factors: RCP x GCM
#		- dat_anova3 = 20'020 cells x 32 (RCPs x GCMs)
#		 => aov-call kills R because of too high memory demand (>16 GB)
#		 => unbalanced design ==> use lme/lmer instead of aov
#
#	4) Variance partitioning based on variances of a lmer() fit
#		- Error strata = (Cell|RCP) + (Cell|GCM) + (1|Shift)
#		- subject = factor(cell)
#		- between-subject factors: region x shift
#		- within-subject factors: RCP x GCM
#		- dat_anova3 = 20'020 cells x 32 (RCPs x GCMs)
#		 ==> lmer-call kills R: Error in match.fun(FUN) : node stack overflow
#
#	5) Variance partitioning based on sums of squares of an aov() fit
#		- y ~ Region + Shift + GCM * RCP
#		- y ~ Region + GCM + RCP + GCM:RCP + Shift:GCM:RCP + Region:Shift:GCM:RCP
#		- y ~ Region + Shift + GCM + RCP + GCM:RCP + Shift:GCM:RCP + Region:Shift:GCM:RCP
#		- dat_anova3 = 20'020 cells x 32 (RCPs x GCMs)
#		 ==> ignoring error strata
#		 ==> results available
#
#	6) Variation partitioning based on variances of sub-group means
#		- calculate variance among sub-group means for each factor
#		- influence of each region on variation partitioning
#		 ==> incorrect because var(means) and not df * var(means)?
#		 ==> incorrect because var(means) and not sum(obs - group.means)^2?
#		 ==> results available
#
#	7) Variation partitioning based on additive elements by Whittaker 1984 using sum of squares
#		 ==> assumes additivity, but it looks like we have strong interactions
#		 ==> results available
#
#	8) Variation partitioning based on adjusted R2 based on ideas in vegan::varpart and vegandocs("partitioning.pdf") AND additive elements by Whittaker 1984
#		 ==> assumes additivity, but it looks like we have strong interactions
#		 ==> results available
#
#	9) Variable importance based on model selection with AICc
#		 ==> results available, but useless
#		 ==> best model ( = full model) is so much better that it has weight = 1; thus all terms have weight = 1 as well and don't discriminate
#
#	20150513: decision
#		- do_compare_methods (for "MAP_mm_mean", "AbsChangeInMean"): all attempts very similar, except Region:Shift:GCM:RCP and attempt6 moves variation from GCMs to regions
#		- use Whittaker 1984-based attempt7 because readily citable and easy to explain, but assumes additivity -> all(do_partition, do_attempt[[7]], do_attempt[(1:9)[-7]])
#
#	20150528: analysis carried out -> all(do_aggregation)
#		- 'AbsChangeInMean': describes climate change impacts ==> interesting for this project; 'Mean': describes mostly geographic variation
#		 ==> means across variable groups: relative importance of factors (Table_VariationPartitioning_Means_XXX_AbsChangeInMean.csv)
#		 ==> mean variance ratios (weighted by overall mean across factors) across variable groups for leave-1-region-out statistics: < 1, region adds to total variation; > 1, region reduces total variation (Table_VariationPartitioning_RelativeRegionVariances_XXX_AbsChangeInMean.csv)

# TODO
#	- limit/select subset of variables per result object (resList)
#	- perform circular scale, lm, etc. for DAY-OF-YEAR variables: only implemented for attempt 7 and 8 (additive elements by Whittaker and Legendre)
###################################################################

comp <- "dropbox"
#---GLOBAL SETTINGS

# Tasks
do_partition <- TRUE	# TRUE, partitioning the variation with any of the do_attempt methods
do_aggregation <- TRUE	# TRUE, aggregate the partitioning for the requested groups of variables

do_attempt <- vector("list", length = 9)
names(do_attempt) <- c("1_aov_Error(Cell/(RCP * GCM))", "2_aov_Error(Cell/(Shift * RCP * GCM))",
						"3_aov_Error(Cell/(Shift * RCP * GCM))", "4_lmer_(Cell|RCP) + (Cell|GCM) + (1|Shift)",
						"5_aov_NoErrorStrata", "6_Variance of sub-group means",
						"7_Whittaker1984_Additive_Elements", "8_Legendre2012_Adjusted R2", "9_AIC variable importance")
do_attempt[[1]] <- FALSE	#aov() fit with Error(Cell/(RCP * GCM))
do_attempt[[2]] <- FALSE	#aov() fit with Error(Cell/(shift * RCP * GCM)); incorrectly formatted data
do_attempt[[3]] <- FALSE	#aov() fit with Error(Cell/(shift * RCP * GCM))
do_attempt[[4]] <- FALSE	#lmer() fit with error strata (Cell|RCP) + (Cell|GCM) + (1|Shift)
do_attempt[[5]] <- FALSE	#aov() fit ignoring error strata
do_attempt[[6]] <- FALSE	#variances of sub-group means
do_attempt[[7]] <- TRUE		#additive elements by Whittaker 1984 using sum of squares
do_attempt[[8]] <- FALSE	#Legendre & Legendre 2012: variation partitioning using adjusted R2, equivalent to Whittaker 1984 for univariate models
do_attempt[[9]] <- FALSE	#Variable importance based on model selection with AICc
do_compare_methods <- FALSE	#Compares attempts

if (any(as.logical(do_attempt[1:6]), do_compare_methods)) { # attempts 1:6 only available in first version of analysis at file.path(dir.gtd, "Prj03_GlobalVulnerability", "4_Analysis", "1_Analysis_v1")
	old <- TRUE
	warning("Attempts 1:6 only implemented with first version of analysis; they will likely fail here")
} else {
	old <- FALSE
}

#-------------------------------
#---R packages
pkg_reqd <- c("reshape2", "car")
has_loaded <- sapply(pkg_reqd,
	function(lib) require(lib, character.only = TRUE, quietly = FALSE))
stopifnot(has_loaded)

#---Load data and misc. functions
if (comp %in% c("err", "eleos")) {
	dir.gtd <- "/PATH_TO_PROJECT/Product_PowellCenter/6_Projects_Year1"
} else if (comp == "dropbox") {
	dir.gtd <- "/PATH_TO_PROJECT/Product_PowellCenter/6_Projects_Year1"
}
dir.prj <- file.path(dir.gtd, "Prj03_GlobalVulnerability", "4_Analysis", "4_Analysis_v4")


get_precalculations <- TRUE
get_studyareaextents <- TRUE
source(file.path(dir.prj, "5a1_GTD_Prj03v4_Helper.R"))

stopifnot(done_precalculations, done_studyareaextents)


#---Directories
if (old) dir.outM <- file.path(dir.sana, "2_StudyAreaMasks", "6_Results_v2")
dir.create(dir.out_RV <- file.path(dir.prj, "6_Results", "6_VariationPartitioning"), showWarnings = FALSE)
dir.create(dir.out_RV1 <- file.path(dir.out_RV, "Tables_Responses"), showWarnings = FALSE)
dir.create(dir.out_RV2 <- file.path(dir.out_RV, "Tables_Aggregated"), showWarnings = FALSE)
dir.create(dir.out_RV3 <- file.path(dir.out_RV, "Figures_Aggregated"), showWarnings = FALSE)


#-------------------------------
if (old) {
	#load: studyarea_array_scenarios, studyarea_scenarios, studyarea_shifts_scenarios
	load(file.path(dir.outM, "1_StudyAreaMasks", "StudyArea_descriptors.RData"))
}

#-------------------------------
if (old) {
	prepare_data_v1 <- function(data, region_data, i_subset = NULL, only_complete = TRUE) {
		# Subset data to study area
		# NOTE: this creates cells x RCP x GCM + region (with many empty 'cells')

		dat_GCMs1 <- array(NA, dim = dim(data), dimnames = dimnames(data))
		for (ircp in seq_along(reqRCPs)) {	
			for (igcm in seq_along(reqGCMs)) {
				irow <- is.finite(studyarea_array_scenarios[ie, 1, 1, ]) | is.finite(studyarea_array_scenarios[ie, 1 + ircp, 1 + igcm, ])
				dat_GCMs1[ircp, igcm, irow] <- data[ircp, igcm, irow]
			}
		}

		# Prepare data for ANOVA without shift in long format
		dat_anova1 <- melt(aperm(dat_GCMs1, perm = 3:1))
		colnames(dat_anova1) <- c("Cell", "GCM", "RCP", "y")
		dat_anova1$Region <- factor(rep(region_data, times = length(reqRCPs) * length(reqGCMs)))
		# Remove unused regions
		i_subset_long <- rep(if (is.null(i_subset)) rep(TRUE, length = dim(dat_GCMs1)[3]) else i_subset, times = length(reqRCPs) * length(reqGCMs))
		dat_anova1 <- dat_anova1[i_subset_long & (dat_anova1$Region %in% label.regions[regions_n]), ] #get rid of the only one cell in South Africa -> 200020 cells
		dat_anova1$Cell <- factor(dat_anova1$Cell)
		if (only_complete) dat_anova1 <- dat_anova1[complete.cases(dat_anova1), ]

		return(dat_anova1)
	}

	prepare_data_v2 <- function(data, region_data, i_subset = NULL, only_complete = TRUE) {			
		# Subset data to study area shifts
		# NOTE: this creates cells x RCP x GCM x shift + region (with many empty 'cells')
		#		but it should be cells x RCP x GCM + region x shift

		dat_GCMs2 <- array(NA, dim = c(dim(data), length(shifts)), dimnames = {temp <- dimnames(data); temp[[length(temp) + 1]] <- shifts; temp})
		for (ircp in seq_along(reqRCPs)) {	
			for (igcm in seq_along(reqGCMs)) {
				irow <- is.finite(studyarea_array_scenarios[ie, 1, 1, ]) | is.finite(studyarea_array_scenarios[ie, 1 + ircp, 1 + igcm, ])
				temp_shift <- studyarea_shifts_scenarios[, grepl(reqRCPs[ircp], colnames(studyarea_shifts_scenarios)) & grepl(gsub("-", ".", reqGCMs[igcm]), colnames(studyarea_shifts_scenarios))]
				for (iss in seq_along(shifts)) {
					ishift <- irow & ifelse(is.finite(temp_shift), temp_shift == shifts_code[iss], FALSE)
					#print(paste(ircp, igcm, iss, sum(ishift)))
					if (sum(ishift) > 0) {
						dat_GCMs2[ircp, igcm, ishift, iss] <- data[ircp, igcm, ishift]
					}
				}
			}
		}

		# Prepare data for ANOVA (RCP x GCM x region x shift + Error(cell:Region)) in long format
		dat_anova2 <- melt(aperm(dat_GCMs2, perm = c(3:1, 4)))
		colnames(dat_anova2) <- c("Cell", "GCM", "RCP", "Shift", "y")
		dat_anova2$Region <- factor(rep(region_data, times = length(shifts) * length(reqRCPs) * length(reqGCMs)))
		# Remove unused regions
		i_subset_long <- rep(if (is.null(i_subset)) rep(TRUE, length = dim(dat_GCMs2)[3]) else i_subset, times = length(reqRCPs) * length(reqGCMs))
		dat_anova2 <- dat_anova2[i_subset_long & (dat_anova2$Region %in% label.regions[regions_n]), ] #get rid of the only one cell in South Africa -> 200020 cells
		dat_anova2$Cell <- factor(dat_anova2$Cell)
		if (only_complete) dat_anova2 <- dat_anova2[complete.cases(dat_anova2), ]

		return(dat_anova2)
	}

	prepare_data_v3 <- function(data, region_data, i_subset = NULL, only_complete = TRUE) {			
		# Subset data to study area shifts
		# NOTE: this creates cells x RCP x GCM + region x shift

		# Subset data to study area shifts
		dat_GCMs3 <- array(NA, dim = c(dim(data), 2), dimnames = {temp <- dimnames(data); temp[[length(temp) + 1]] <- c("y", "Shift"); temp})
		for (ircp in seq_along(reqRCPs)) {	
			for (igcm in seq_along(reqGCMs)) {
				irow <- is.finite(studyarea_array_scenarios[ie, 1, 1, ]) | is.finite(studyarea_array_scenarios[ie, 1 + ircp, 1 + igcm, ])
				temp_shift <- studyarea_shifts_scenarios[, grepl(reqRCPs[ircp], colnames(studyarea_shifts_scenarios)) & grepl(gsub("-", ".", reqGCMs[igcm]), colnames(studyarea_shifts_scenarios))]
				dat_GCMs3[ircp, igcm, irow, "y"] <- data[ircp, igcm, irow]
				dat_GCMs3[ircp, igcm, irow, "Shift"] <- (temp_shift + 2)[irow]
			}
		}

		# Prepare data for ANOVA in long format
		dat_anova3 <- melt(aperm(dat_GCMs3[, , , "y"], perm = 3:1))
		colnames(dat_anova3) <- c("Cell", "GCM", "RCP", "y")
		dat_anova3$Region <- factor(rep(region_data, times = length(reqRCPs) * length(reqGCMs)))
		dat_anova3$Shift <- factor(melt(aperm(dat_GCMs3[, , , "Shift"], perm = 3:1))$value)
		# Remove unused regions
		i_subset_long <- rep(if (is.null(i_subset)) rep(TRUE, length = dim(dat_GCMs3)[3]) else i_subset, times = length(reqRCPs) * length(reqGCMs))
		dat_anova3 <- dat_anova3[i_subset_long & (dat_anova3$Region %in% label.regions[regions_n]), ] #get rid of the only one cell in South Africa -> 200020 cells
		dat_anova3$Cell <- factor(dat_anova3$Cell)
		if (only_complete) dat_anova3 <- dat_anova3[complete.cases(dat_anova3), ]
		# scale
		dat_anova3$sy <- scale(dat_anova3$y)

		return(dat_anova3)
	}
} else {
	prepare_data_v3 <- function(data, region_data, i_subset = NULL, only_complete = TRUE, circular = FALSE) {			
		#str(data): num [1:2, 1:16, 1:20021] NA NA NA NA NA NA NA NA NA NA ...
		# - attr(*, "dimnames") = List of 3
		# ..$ : chr [1:2] "RCP45" "RCP85"
		# ..$ : chr [1:16] "CanESM2" "CESM1-CAM5" "CSIRO-Mk3-6-0" "EC-EARTH" ...
		# ..$ : NULL

		# Subset data to study area shifts
		# NOTE: this creates cells x RCP x GCM + region x shift
		stopifnot(exists("dShift2"))
			
		# Subset data to study area shifts
		dat_GCMs3 <- array(NA, dim = c(dim(data), 2), dimnames = {temp <- dimnames(data); temp[[length(temp) + 1]] <- c("y", "Shift"); temp})
		for (ircp in seq_along(reqRCPs)) {	
			for (igcm in seq_along(reqGCMs)) {
				irow <- !is.na(dShift2[ircp, igcm, , "shifts_code"])
				
				dat_GCMs3[ircp, igcm, irow, "Shift"] <- 2 + dShift2[ircp, igcm, irow, "shifts_code"]
				dat_GCMs3[ircp, igcm, irow, "y"] <- data[ircp, igcm, irow]
			}
		}

		# Prepare data for ANOVA in long format
		dat_anova3 <- melt(aperm(dat_GCMs3[, , , "y"], perm = 3:1))
		colnames(dat_anova3) <- c("Cell", "GCM", "RCP", "y")
		dat_anova3$Region <- factor(rep(region_data, times = length(reqRCPs) * length(reqGCMs)))
		dat_anova3$Shift <- factor(melt(aperm(dat_GCMs3[, , , "Shift"], perm = 3:1))$value)
		# Remove unused regions
		i_subset_long <- rep(if (is.null(i_subset)) rep(TRUE, length = dim(dat_GCMs3)[3]) else i_subset, times = length(reqRCPs) * length(reqGCMs))
		dat_anova3 <- dat_anova3[i_subset_long & (dat_anova3$Region %in% label.regions[regions_n]), ] #get rid of the only one cell in South Africa -> 200020 cells
		dat_anova3$Cell <- factor(dat_anova3$Cell)
		if (only_complete) dat_anova3 <- dat_anova3[complete.cases(dat_anova3), ]
		# scale
		if (circular) {
			dat_anova3$sy <- circ.scale(dat_anova3$y, int = 365)
			
		} else {	
			dat_anova3$sy <- scale(dat_anova3$y)
		}

		return(dat_anova3)
		#str(dat_anova3): 'data.frame':	220569 obs. of 7 variables:
		# $ Cell : Factor w/ 11266 levels "909","910","912",..: 22 23 24 27 28 29 30 31 39 40 ...
		# $ GCM  : Factor w/ 16 levels "CanESM2","CESM1-CAM5",..: 1 1 1 1 1 1 1 1 1 1 ...
		# $ RCP  : Factor w/ 2 levels "RCP45","RCP85": 1 1 1 1 1 1 1 1 1 1 ...
		# $ y   : num 441 404 380 343 327 ...
		# $ Region: Factor w/ 6 levels "Eastern Asia",..: 1 1 1 1 1 1 1 1 5 5 ...
		# $ Shift : Factor w/ 3 levels "1","2","3": 3 3 3 3 3 3 3 3 2 2 ...
		# $ sy  : num [1:220569, 1] 0.9084 0.6181 0.4341 0.1472 0.0225 ...
		# ..- attr(*, "scaled:center") = num 324
		# ..- attr(*, "scaled:scale") = num 128
	}	
}

#-------------------------------
if (do_attempt[[7]]) {
	#Whittaker, J. 1984. Model Interpretation from the Additive Elements of the Likelihood Function. Journal of the Royal Statistical Society. Series C (Applied Statistics) 33:52-64.
	# Residual: G(:1234) = g_1234 = residual variation
	# Primaries: G(1:234) = g1_234 = variation uniquely attributable to x1
	# Secondaries: G(12:34) = g12_34 = variation attributable to x1 or x2 but not to both
	# 3rd order elements: G(123:4) = g123_4 = 
	# 4th order elements: G(1234:) = g1234_ = 

	whittaker_additive_elements <- function(data, X1 = "Region", X2 = "Shift", X3 = "GCM", X4 = "RCP", circular = FALSE) {
		if (var(data$y) > 0) {
		
			if (circular) {
				warning("circular lm not yet implemented, perform instead lm with standardized y")
				
				if (FALSE) {# Example ?lm.circular: Fit a circular-linear regression model
					set.seed(1234)
					x <- cbind(rnorm(10), rep(1, 10))
					y <- circular(2 * atan(c(x %*% c(5,1)))) + rvonmises(10, mu = circular(0), kappa = 100)
				
					temp <- lm.circular(y = y, x = x, init = c(5,1), type = 'c-l', verbose = F)
				
					resids <- circular(2 * atan(c(x %*% temp$coefficients)), modulo = "2pi") - circular(y, modulo = "2pi") # some residuals (which?)
				
					#Residual sum of squares = sum( (yi - predsi)^2 ) = sum( residi^2 )
					RSS <- sum(resids^2)
				}
				if (FALSE) {
					int <- 365
					circ <- 2 * pi / int
					y.circ <- circular(data$y * circ, type = "angles", units = "radians", rotation = "counter", modulo = "2pi")
					x <- data[, c(X1, X2, X3, X4)]
					isnotna <- complete.cases(cbind(y.circ, x))
					xtemp <- model.matrix(as.formula(paste0("~ ", X1, op2, X2, op3, X3, op4, X4)), x)
					xcS <- apply(xtemp[isnotna, ], 2, sum)
					if (any(itemp <- (xcS < 2))) xtemp <- xtemp[, !itemp]
					
					#This will likely fail either due to too large memory needs or instability in beta estimates and convergence to 0 and then to NA in the function circular:::LmCircularclRad(), line: betaNew <- lm(t(D) %*% (u + A %*% D %*% betaPrev) ~ t(D) %*% A %*% D - 1)$coefficients
					m <- try(lm.circular(y = y.circ[isnotna], x = xtemp[isnotna, ], init = rep(1, ncol(xtemp)), type = "c-l", verbose = F))
					
					if (!inherits(m, "try-error")) {
						resids <- minusPiPlusPi(circular(xtemp[isnotna, ] %*% m$coefficients, modulo = "2pi") - y.circ[isnotna]) / circ #I am not sure whether these residuals are correct
						#Residual sum of squares = sum( (yi - predsi)^2 ) = sum( residi^2 )
						RSS <- sum(resids^2)
					} else {
						RSS <- NA
					}
				}
				
				if (TRUE) {#until circular lm is implemented well
					data$y <- data$sy
				}
				
			}
		
		
			f <- function(m) tail(Anova(m, type = 2)[, "Sum Sq"], n = 1) #it has no influence what SS-type we use because we only extract residual SS
		
			op1 <- if (!is.null(X1)) "+" else NULL
			op2 <- if (!is.null(X2)) "+" else NULL
			op3 <- if (!is.null(X3)) "+" else NULL
			op4 <- if (!is.null(X4)) "+" else NULL
			
			#Total
			gtotal <- f(lm(y ~ 1, data = data))
	
			#Residual
			g_1234 <- f(lm(paste0("y ~ ", X1, op2, X2, op3, X3, op4, X4), data = data))

			# Primaries
			g1_234 <- f(lm(paste0("y ~ ", X2, op3, X3, op4, X4), data = data)) - g_1234
			g2_134 <- f(lm(paste0("y ~ ", X1, op3, X3, op4, X4), data = data)) - g_1234
			g3_124 <- f(lm(paste0("y ~ ", X1, op2, X2, op4, X4), data = data)) - g_1234
			g4_123 <- f(lm(paste0("y ~ ", X1, op2, X2, op3, X3), data = data)) - g_1234

			#Secondaries
			g12_34 <- if (!is.null(X3) || !is.null(X4)) f(lm(paste0("y ~ ", X3, op4, X4), data = data)) - g_1234 - g1_234 - g2_134 else 0
			g13_24 <- if (!is.null(X2) || !is.null(X4)) f(lm(paste0("y ~ ", X2, op4, X4), data = data)) - g_1234 - g1_234 - g3_124 else 0
			g14_23 <- if (!is.null(X2) || !is.null(X3)) f(lm(paste0("y ~ ", X2, op3, X3), data = data)) - g_1234 - g1_234 - g4_123 else 0
			g23_14 <- if (!is.null(X1) || !is.null(X4)) f(lm(paste0("y ~ ", X1, op4, X4), data = data)) - g_1234 - g2_134 - g3_124 else 0
			g24_13 <- if (!is.null(X1) || !is.null(X3)) f(lm(paste0("y ~ ", X1, op3, X3), data = data)) - g_1234 - g2_134 - g4_123 else 0
			g34_12 <- if (!is.null(X1) || !is.null(X2)) f(lm(paste0("y ~ ", X1, op2, X2), data = data)) - g_1234 - g3_124 - g4_123 else 0

			#Order 3:
			g123_4 <- if (!is.null(X4)) f(lm(paste0("y ~ ", X4), data = data)) - g_1234 - g1_234 - g2_134 - g3_124 - g12_34 - g13_24 - g23_14 else 0
			g124_3 <- if (!is.null(X3)) f(lm(paste0("y ~ ", X3), data = data)) - g_1234 - g1_234 - g2_134 - g4_123 - g12_34 - g14_23 - g24_13 else 0
			g134_2 <- if (!is.null(X2)) f(lm(paste0("y ~ ", X2), data = data)) - g_1234 - g1_234 - g3_124 - g4_123 - g13_24 - g14_23 - g34_12 else 0
			g234_1 <- if (!is.null(X1)) f(lm(paste0("y ~ ", X1), data = data)) - g_1234 - g2_134 - g3_124 - g4_123 - g23_14 - g24_13 - g34_12 else 0

			#Order 4:
			g1234_ <- gtotal - g_1234 - g1_234 - g2_134 - g3_124 - g4_123 - g12_34 - g13_24 - g14_23 - g23_14 - g24_13 - g34_12 - g123_4 - g124_3 - g134_2 - g234_1
		

			#Relative elements
			probs <- round(100 * c(g_1234, g1_234, g2_134, g3_124, g4_123, g12_34, g13_24, g14_23, g23_14, g24_13, g34_12, g123_4, g124_3, g134_2, g234_1, g1234_) / gtotal, 1)
			names(probs) <- c("Residuals",
								paste0("Primary_", c(X1, X2, X3, X4)),
								paste0("Secondary_", c(paste0(X1, ":", X2), paste0(X1, ":", X3), paste0(X1, ":", X4), paste0(X2, ":", X3), paste0(X2, ":", X4), paste0(X3, ":", X4))),
								paste0("Tertiary_", c(paste0(X1, ":", X2, ":", X3), paste0(X1, ":", X2, ":", X4), paste0(X1, ":", X3, ":", X4), paste0(X2, ":", X3, ":", X4))),
								paste0("Quartery_", X1, ":", X2, ":", X3, ":", X4))

			if (interactive()) {
				plot(0, probs[1], xlim = c(-0.5, 5.5), ylim = range(probs))
				points(rep(1, 4), probs[2:5])
				points(rep(2, 6), probs[6:11])
				points(rep(3, 4), probs[12:15])
				points(4, probs[16])
				abline(h = 0)
			}
		} else {
			probs <- rep(NA, times = 16)
			gtotal <- 0
		}
	
		return(list(probs = probs, total = gtotal))
	}

	if (FALSE) {#Test code to match up with cement example of Whittaker 1984
		library(MuMIn)
		data(Cement)
	
		probs_cement <- whittaker_additive_elements(data = Cement, X1 = "X1", X2 = "X2", X3 = "X3", X4 = "X4")$probs
		#Residual      Primary_X1      Primary_X2      Primary_X3      Primary_X4   Secondary_X1:X2   Secondary_X1:X3   Secondary_X1:X4   Secondary_X2:X3   Secondary_X2:X4   Secondary_X3:X4  Tertiary_X1:X2:X3  Tertiary_X1:X2:X4  Tertiary_X1:X3:X4  Tertiary_X2:X3:X4 Quartery_X1:X2:X3:X4 
		#	 1.8         1.0         0.1         0.0         0.0         3.6         29.3         12.6         0.9         43.3         0.4         -4.1         9.1        -11.6         0.2         13.5 
	}
}

if (do_attempt[[8]]) {
	#Legendre, P., and L. Legendre. 2012. Numerical ecology. Third English edition. edition. Elsevier, Amsterdam.
	# - p. 570-583: 5 — Partial linear regression and variation partitioning
	# - vegan::varpart and vegandocs("partitioning.pdf")
	# A negative fraction [b] indicates that two variables (or groups of variables X and W), together, explain y better than the sum of the individual effects of these variables. This can happen: see Numerical examples 2 and 3. Fraction [b] is the intersection of the variation explained by linear models of X and W. It is not an interaction in the ANOVA sense.
	
	legendre_varpart <- function(data, X1 = "Region", X2 = "Shift", X3 = "GCM", X4 = "RCP", circular = FALSE) {
		if (var(data$y) > 0) {
			f <- function(m) summary(m)$adj.r.squared
		
			op1 <- if (!is.null(X1)) "+" else NULL
			op2 <- if (!is.null(X2)) "+" else NULL
			op3 <- if (!is.null(X3)) "+" else NULL
			op4 <- if (!is.null(X4)) "+" else NULL
			
			#Direct analysis
			p1 <- if (!is.null(X1)) f(lm(paste0("y ~ ", X1), data = data)) else 0	# aeghklno
			p2 <- if (!is.null(X2)) f(lm(paste0("y ~ ", X2), data = data)) else 0	# befiklmo
			p3 <- if (!is.null(X3)) f(lm(paste0("y ~ ", X3), data = data)) else 0	# cfgjlmno
			p4 <- if (!is.null(X4)) f(lm(paste0("y ~ ", X4), data = data)) else 0	# dhijkmno
		
			p12 <- if (!is.null(X1) || !is.null(X2)) f(lm(paste0("y ~ ", X1, op2, X2), data = data)) else 0	# abefghiklmno
			p13 <- if (!is.null(X1) || !is.null(X3)) f(lm(paste0("y ~ ", X1, op3, X3), data = data)) else 0	# acefghjklmno
			p14 <- if (!is.null(X1) || !is.null(X4)) f(lm(paste0("y ~ ", X1, op4, X4), data = data)) else 0	# adeghijklmno
			p23 <- if (!is.null(X2) || !is.null(X3)) f(lm(paste0("y ~ ", X2, op3, X3), data = data)) else 0	# bcefgijklmno
			p24 <- if (!is.null(X2) || !is.null(X4)) f(lm(paste0("y ~ ", X2, op4, X4), data = data)) else 0	# bdefhijklmno
			p34 <- if (!is.null(X3) || !is.null(X4)) f(lm(paste0("y ~ ", X3, op4, X4), data = data)) else 0	# cdfghijklmno
		
			p123 <- if (!is.null(X1) || !is.null(X2) || !is.null(X3)) f(lm(paste0("y ~ ", X1, op2, X2, op3, X3), data = data)) else 0	# abcefghijklmno
			p124 <- if (!is.null(X1) || !is.null(X2) || !is.null(X4)) f(lm(paste0("y ~ ", X1, op2, X2, op4, X4), data = data)) else 0	# abdefghijklmno
			p134 <- if (!is.null(X1) || !is.null(X3) || !is.null(X4)) f(lm(paste0("y ~ ", X1, op3, X3, op4, X4), data = data)) else 0	# acdefghijklmno
			p234 <- if (!is.null(X2) || !is.null(X3) || !is.null(X4)) f(lm(paste0("y ~ ", X2, op3, X3, op4, X4), data = data)) else 0	# bcdefghijklmno

			p1234 <- f(lm(paste0("y ~ ", X1, op2, X2, op3, X3, op4, X4), data = data)) # abcdefghijklmno = all
		
			#Partial analysis controlling for one variable
			p1_2 <- p12 - p2	# aghn
			p1_3 <- p13 - p3	# aehk
			p1_4 <- p14 - p4	# aegl
			p2_1 <- p12 - p1	# bfim
			p2_3 <- p23 - p3	# beik
			p2_4 <- p24 - p4	# befl
			p3_1 <- p13 - p1	# cfjm
			p3_2 <- p23 - p2	# cgjn
			p3_4 <- p34 - p4	# cfgl
			p4_1 <- p14 - p1	# dijm
			p4_2 <- p24 - p2	# dhjn
			p4_3 <- p34 - p3	# dhik

			#Partial analysis controlling for two variables
			p1_34 <- p134 - p34	# ae
			p1_24 <- p124 - p24	# ag
			p1_23 <- p123 - p23	# ah
			p2_34 <- p234 - p34	# be
			p2_14 <- p124 - p14	# bf
			p2_13 <- p123 - p13 # bi
			p3_14 <- p134 - p14	# cf
			p3_24 <- p234 - p24	# cg
			p3_12 <- p123 - p12	# cj
			p4_23 <- p234 - p23	# dh
			p4_13 <- p134 - p13	# di
			p4_12 <- p124 - p12	# dj
		
			#Partial analysis controlling for three variables
			p1_234 <- p1234 - p234	# a, i.e., 1 without union {2, 3, 4}
			p2_134 <- p1234 - p134	# b
			p3_124 <- p1234 - p124	# c
			p4_123 <- p1234 - p123	# d
		
			p12_34 <- p1_34 - p1_234	# e, i.e. intersection {1, 2} without union {3, 4}
			p23_14 <- p2_14 - p2_134	# f
			p13_24 <- p1_24 - p1_234	# g
			p14_23 <- p1_23 - p1_234	# h
			p24_13 <- p2_13 - p2_134	# i
			p34_12 <- p3_12 - p3_124	# j
		
			p124_3 <- p1_3 - p1_34 - p14_23 # k
			p123_4 <- p1_4 - p1_34 - p13_24	# l, i.e. intersection {1, 2, 3} without 4
			p234_1 <- p2_1 - p2_14 - p24_13	# m
			p134_2 <- p1_2 - p1_24 - p14_23	# n
			p1234_ <- p1 - p1_3 - p13_24 - p123_4 - p134_2 # o, i.e., intersection {1, 2, 3, 4}
		
			#Fractions estimated by subtraction
			presid <- 1 - p1234 #p = residuals = 1 - all
		

			#Relative elements
			probs <- round(100 * c(presid, p1_234, p2_134, p3_124, p4_123, p12_34, p13_24, p14_23, p23_14,
			p24_13, p34_12, p123_4, p124_3, p134_2, p234_1, p1234_), 1)
			names(probs) <- c("Residuals",
								paste0("Primary_", c(X1, X2, X3, X4)),
								paste0("Secondary_", c(paste0(X1, ":", X2), paste0(X1, ":", X3), paste0(X1, ":", X4), paste0(X2, ":", X3), paste0(X2, ":", X4), paste0(X3, ":", X4))),
								paste0("Tertiary_", c(paste0(X1, ":", X2, ":", X3), paste0(X1, ":", X2, ":", X4), paste0(X1, ":", X3, ":", X4), paste0(X2, ":", X3, ":", X4))),
								paste0("Quartery_", X1, ":", X2, ":", X3, ":", X4))
			
			if (interactive()) {
				plot(0, probs[1], xlim = c(-0.5, 5.5), ylim = range(probs))
				points(rep(1, 4), probs[2:5])
				points(rep(2, 6), probs[6:11])
				points(rep(3, 4), probs[12:15])
				points(4, probs[16])
				abline(h = 0)
			}			
		} else {
			probs <- rep(NA, times = 16)
		}

	
		return(probs)
	}
	
	if (FALSE) {#Test code to match up with
		fertil.spe <- read.delim ('http://www.davidzeleny.net/anadat-r/data-download/fertil.spe.txt', row.names = 1)
		fertil.env <- read.delim ('http://www.davidzeleny.net/anadat-r/data-download/fertil.env.txt', row.names = 1)
		save(fertil.spe, fertil.env, file = file.path(dir.out, "Example_data_DavidZeleny.RData"))
		
		varp <- varpart(fertil.spe, ~ dose, ~ cover, data = fertil.env)
		#Partition table:
		#           Df R.squared Adj.R.squared Testable
		#[a+b] = X1      1  0.06889    0.06113   TRUE
		#[b+c] = X2      1  0.09628    0.08875   TRUE
		#[a+b+c] = X1+X2    2  0.14304    0.12864   TRUE
		#Individual fractions                  
		#[a] = X1|X2      1         0.03988   TRUE
		#[b]          0         0.02125  FALSE
		#[c] = X2|X1      1         0.06750   TRUE
		#[d] = Residuals             0.87136  FALSE
		
		varp <- varpart(fertil.spe[, 1], ~ dose, ~ cover, data = fertil.env)
		#Partition table:
		#					  Df R.squared Adj.R.squared Testable
		#[a+b] = X1      1  0.12106    0.11373   TRUE
		#[b+c] = X2      1  0.10846    0.10103   TRUE
		#[a+b+c] = X1+X2    2  0.13135    0.11675   TRUE
		#Individual fractions                  
		#[a] = X1|X2      1         0.01572   TRUE
		#[b]          0         0.09801  FALSE
		#[c] = X2|X1      1         0.00302   TRUE
		#[d] = Residuals             0.88325  FALSE
		
		fertil_dz1 <- data.frame(y = fertil.spe[, 1], fertil.env)
		test8a <- legendre_varpart(data = fertil_dz1, X1 = "dose", X2 = "cover", X3 = NULL, X4 = NULL)
	}
}
#-------------------------------


#---Setup
if (old) {
	resList <- c("res.ClimateSpace", "res.Climate", "res.SWat", "res.Veg", "res.WatRes", "res.Extra1", "res.RegionOverview")
	typeList <- c("Mean", response_types[1])
	#typeList <- response_types[1]
	considered_cells <- apply(res.Definition$dStudy, 4, function(x) any(as.logical(x), na.rm = TRUE)) # use cells that are in study area at least under one of the 33 climate conditions

	variables <- unlist(sapply(resList, function(x) dimnames(get(x)$valCur)[[5]]))
} else {
	resList <- sets_names_extracted2[-3]
	typeList <- change_types
	considered_cells <- apply(dStudy2["MetDef_Any17Cond", , currentSc, ], 2, function(x) any(!is.na(x))) #take either RCP extent
	#variables <- unlist(sapply(resList, function(x) dimnames(get(x))[[5]]))
	variables <- unlist(temp <- list(var_climate, var_response_sel, var_soils, var_veg))
	names(variables) <- rep(resList, times = sapply(temp, length))
}

factors <- c("Residuals", "Region", "Shift", "GCM", "RCP", "Region:Shift", "Region:GCM", "Region:RCP", "Shift:GCM", "Shift:RCP", "GCM:RCP", "Region:Shift:GCM", "Region:Shift:RCP", "Region:GCM:RCP", "Shift:GCM:RCP", "Region:Shift:GCM:RCP")
factors <- c("Cells", "Region", "Shift", "GCM", "RCP", "Region:Shift", "Region:GCM", "Region:RCP", "Shift:GCM", "Shift:RCP", "GCM:RCP", "Region:Shift:GCM", "Region:Shift:RCP", "Region:GCM:RCP", "Shift:GCM:RCP", "Region:Shift:GCM:RCP")


#---do the variation partitioning
ftag_prop <- "Table_VariancePartitioning_RelativeProportions"
if (do_partition && any(as.logical(do_attempt))) {

	#Function to partition variation
	do_varpart_regional_response <- function(ie = 1, type = c("Mean", "AbsoluteChange", "RelativeChange"), res_data, varname, i_subset) {
		#Example output based on MAP_mm_mean
		#---------------Prepare data
		i_subset <- i_subset & considered_cells
		
		temp_type <- if (identical(type, "Mean")) "AbsChangeInMean" else type
		
		
		if (old) {
			is_circular <- FALSE
			comp_data <- compile_Response(type = type, ie = ie, cur = res_data$valCur["Full", ie, "Mean", , varname], sc = res_data$res["Full", ie,,, temp_type, , varname])[ie, -1, -1, ]

			if (do_attempt[[1]]) {
				dat_anova1 <- prepare_data_v1(data = comp_data, region_data = label.regions[res_data$dLoc$Region], i_subset = i_subset)
			} else if (do_attempt[[2]]) {
				dat_anova2 <- prepare_data_v2(data = comp_data, region_data = label.regions[res_data$dLoc$Region], i_subset = i_subset)
			} else {
				dat_anova3 <- prepare_data_v3(data = comp_data, region_data = label.regions[res_data$dLoc$Region], i_subset = i_subset)
			}
			rm(comp_data)
		} else {
			if (!do_attempt[[1]] && !do_attempt[[2]]) {
				is_circular <- grepl("_doy", varname)
				comp_data <- dat_sweep(dat = res_data[, -1, -1, , varname], dat_cur = res_data["Simulation", currentSc, currentSc, , varname], val_type = type, circular = is_circular)
				dat_anova3 <- prepare_data_v3(data = comp_data["MetDef_ThisCond", , ,], region_data = label.regions[dLoc$Region], i_subset = i_subset, circular = is_circular)
			} else {
				stop("Attempts 1 and 2 not implemented for !old analysis version")
			}
		}
		#---------------

		
		#---------------MODEL1: aov with Error(Cell/(RCP * GCM)), no shift
		if (do_attempt[[1]]) {
			factors <- c('cells', 'RCP', 'GCM', 'region', 'shift', 'RCP:GCM', 'RCP:region','GCM:region', 'RCP:shift', 'GCM:shift', 'region:shift', 'RCP:GCM:region', 'RCP:GCM:shift', 'RCP:region:shift', 'GCM:region:shift', 'RCP:GCM:region:shift', 'Residuals')
			# fit model: aov-call kills R because of too high memory demand (>16 GB)
			if (FALSE) {
				stop("fit model: aov-call kills R because of too high memory demand (>16 GB)")
				m1 <- aov(y ~ RCP * GCM * Region + Error(Cell/(RCP * GCM)), data = dat_anova1t)
			}
		
			#extract SS
			prop <- as.data.frame(matrix(NA, nrow = length(factors), ncol = 3))
			colnames(prop) <- c('factor', 'SS', 'prop')
			prop[, 'factor'] <- factors

			#extract sum of squares
			#prop[1, "SS"] <- summary(fit)[["Error: Cell:Region"]][[1]][, "Sum Sq"] # Error: cells -> SS error
			#prop[-1, "SS"] <- summary(fit)[["Error: Within"]][[1]][, "Sum Sq"] # Error: Within -> SS factors
	
			prop[, "SS"] <- summary(fit)[["Error: Within"]][[1]][, "Sum Sq"]

			#calculate proportion of variation explained
			prop[, "prop"] <- as.numeric(prop[, "SS"]) / sum(as.numeric(prop[, "SS"]))
		
			#unbalanced design ==> use lme/lmer instead of aov
			replications(y ~ RCP * GCM * Region + Error(Cell/(RCP * GCM)), data = dat_anova1)


		}			
		#---------------

		#---------------MODEL2: aov with Error(Cell/(RCP * GCM * shift))
		if (do_attempt[[2]]) {
			# ==> INCORRECT FORMULATION: this creates cells x RCP x GCM x shift + region (with many empty 'cells') but it should be cells x RCP x GCM + region x shift
		}
		#---------------

		#---------------MODEL3: aov with Error(Cell/(RCP * GCM)), with shift * region
		if (do_attempt[[3]]) {
			if (FALSE) {	# fit model: aov-call kills R because of too high memory demand (>16 GB)
				m3a <- aov(y ~ RCP * GCM * Region * Shift + Error(Cell/(RCP * GCM)), data = dat_anova3) 
				m3b <- aov(y ~ RCP * GCM * Region * Shift + Error(Cell/(Shift * RCP * GCM)), data = dat_anova3)
			}
			
			#unbalanced design ==> use lme/lmer instead of aov
			replications(y ~ RCP * GCM * Region * Shift + Error(Cell/(Shift * (RCP * GCM))), data = dat_anova3)
			replications(y ~ RCP * GCM * Region * Shift, data = dat_anova3)
			plot.design(y ~ Region * Shift * RCP * GCM, data = dat_anova3)
			
		}
		#---------------

		#---------------MODEL4: lmer with (Cell|RCP) + (Cell|GCM) + (1|Shift)
		if (do_attempt[[4]]) {
			library(lme4)
			
			if (FALSE) { #small test subsets: not done after 3 days of running...
				dat_anova3t <- dat_anova3
				dat_anova3tt <- dat_anova3t[dat_anova3t$Region %in% 6 & !is.na(dat_anova3t$y), ]
				dat_anova3tt <- dat_anova3tt[dat_anova3tt$Cell %in% sample(x = dat_anova3tt$Cell, size = round(0.001*length(dat_anova3tt$Cell))), ]
				dat_anova3tt$Cell <- factor(dat_anova3tt$Cell)
				dat_anova3tt$Region <- factor(dat_anova3tt$Region)
				dat_anova3tt$Shift <- factor(dat_anova3tt$Shift)
				dat_anova3tt$sy <- scale(dat_anova3tt$y)
				dim(dat_anova3tt) #1539  7
				
				#Suggestion by Lukas (U of Bern, CAS teaching assistant)
				m4a <- lmer(sy ~ GCM * RCP + (Cell|RCP) + (Cell|GCM) + (1|Shift), data = dat_anova3tt, na.action = na.exclude)
				
			}

			if (FALSE) {# full models fail because of memory
				#remove region 5 because of empty cells
				dat_anova4 <- dat_anova3[dat_anova3$Region %in% c(1, 3, 4, 6), ]
				dat_anova4$GCMxRCP <- with(dat_anova4, interaction(GCM, RCP))
				dat_anova4$Region <- factor(dat_anova4$Region)
				dat_anova4$Cell <- factor(dat_anova4$Cell)
				dat_anova4$Shift <- factor(dat_anova4$Shift)
				dat_anova4$sy <- scale(dat_anova4$y)

				m4b <- lmer(y ~ Region + GCM * RCP + (Cell|RCP) + (Cell|GCM) + (1|Shift), data = dat_anova4, na.action = na.exclude)
				# Error in match.fun(FUN) : node stack overflow

				m4c <- lmer(y ~ 1 + Region + Shift + GCM * RCP + (Cell|Region), data = dat_anova3, na.action = na.exclude)

			}
		}
		#---------------

		#---------------ALTERNATIVE5: AOV IGNORING ERROR-STRUCTURE
		if (do_attempt[[5]]) {
			m5a <- lm(y ~ Region + Shift + GCM * RCP, data = dat_anova3)
			m5b <- lm(y ~ Region + GCM + RCP + GCM:RCP + Shift:GCM:RCP + Region:Shift:GCM:RCP, data = dat_anova3)
			m5c <- lm(y ~ Region + Shift + GCM + RCP + GCM:RCP + Shift:GCM:RCP + Region:Shift:GCM:RCP, data = dat_anova3)

			prop5a <- round(100 * (temp <- Anova(m5a, type = 2))[, "Sum Sq"] / sum(temp[, "Sum Sq"]), 1)
			#       Sum Sq   Df F value  Pr(>F)  
			#Region   97964328   4 9068.18 < 2.2e-16 ***
			#Shift    5663577   2 1048.51 < 2.2e-16 ***
			#GCM    152406266   15 3762.04 < 2.2e-16 ***
			#RCP     8573511   1 3174.47 < 2.2e-16 ***
			#GCM:RCP  16906967   15 417.34 < 2.2e-16 ***
			#Residuals 932236437 345174           
			names(prop5a) <- rownames(temp)
			#  Region   Shift    GCM    RCP  GCM:RCP Residuals 
			#   8.1    0.5   12.6    0.7    1.4   76.8 
			
			prop5b <- round(100 * (temp <- Anova(m5b, type = 2))[, "Sum Sq"] / sum(temp[, "Sum Sq"]), 1)
			#            Sum Sq   Df F value  Pr(>F)  
			#Region        98982461   4 11208.59 < 2.2e-16 ***
			#GCM         160224553   15 4838.27 < 2.2e-16 ***
			#RCP          9757279   1 4419.58 < 2.2e-16 ***
			#GCM:RCP        17498584   15  528.40 < 2.2e-16 ***
			#GCM:RCP:Shift     24333928   64  172.22 < 2.2e-16 ***
			#Region:GCM:RCP:Shift 152470781  372  185.65 < 2.2e-16 ***
			#Residuals      761095304 344740            
			names(prop5b) <- rownames(temp)
			#Region         GCM         RCP       GCM:RCP    GCM:RCP:Shift Region:GCM:RCP:Shift      Residuals 
			#  8.1         13.1         0.8         1.4         2.0         12.5         62.2 

			prop5c <- round(100 * (temp <- Anova(m5c, type = 2))[, "Sum Sq"] / sum(temp[, "Sum Sq"]), 1)
			#            Sum Sq   Df F value  Pr(>F)  
			#Region        98982461   4 11208.59 < 2.2e-16 ***
			#Shift         5663577   2 1282.67 < 2.2e-16 ***
			#GCM         152406266   15 4602.19 < 2.2e-16 ***
			#RCP          8573511   1 3883.39 < 2.2e-16 ***
			#GCM:RCP        16906967   15  510.54 < 2.2e-16 ***
			#Shift:GCM:RCP     18670352   62  136.40 < 2.2e-16 ***
			#Region:Shift:GCM:RCP 152470781  372  185.65 < 2.2e-16 ***
			#Residuals      761095304 344740            
			names(prop5c) <- rownames(temp)
			#Region        Shift         GCM         RCP       GCM:RCP    Shift:GCM:RCP Region:Shift:GCM:RCP      Residuals 
			#  8.1         0.5         12.5         0.7         1.4         1.5         12.6         62.7 


			if (FALSE) { #Variance partitioning by hand TSS = ESS + RSS, using region as example
				fit2r <- aov(y ~ Region, data = dat_anova3)

				total_mean <- mean(dat_anova3$y, na.rm = TRUE)
				yhat_r <- with(dat_anova3, r_means$x[match(Region, r_means[, 1])])
				yhat_r[is.na(dat_anova3$y)] <- NA
				ess <- sum((yhat_r - total_mean)^2, na.rm = TRUE)
				rss <- sum((dat_anova3$y - yhat_r)^2, na.rm = TRUE)
				tss <- sum((dat_anova3$y - total_mean)^2, na.rm = TRUE)
				all.equal(summary(fit2r)[[1]][1, 2], ess)
				all.equal(summary(fit2r)[[1]][2, 2], rss)
				all.equal(sum(summary(fit2r)[[1]][, 2]), tss)
			}
		}
		#---------------
		
		#---------------ALTERNATIVE6: COMPARE VARIANCES OF SUB-GROUP MEANS
		if (do_attempt[[6]]) {
			#	- incorrect because var(means) and not df * var(means)?
			#	- incorrect because var(means) and not sum(obs - group.means)^2?

			#data
			factors1 <- c("Residuals", "Region", "Shift", "GCM", "RCP", "RCP:GCM", "Shift:RCP:GCM", "Region:Shift:RCP:GCM")
			factors2 <- c("Region", "Shift", "Region x Shift", "Region x GCM x RCP", "Shift x GCM x RCP", "Region x Shift x GCM x RCP")

			cell_means <- with(dat_anova3, aggregate(y, by = list(Cell), mean, na.rm = TRUE))

			r_means <- with(dat_anova3, aggregate(y, by = list(Region), mean, na.rm = TRUE))
			s_means <- with(dat_anova3, aggregate(y, by = list(Shift), mean, na.rm = TRUE))
			g_means <- with(dat_anova3, aggregate(y, by = list(GCM), mean, na.rm = TRUE))
			c_means <- with(dat_anova3, aggregate(y, by = list(RCP), mean, na.rm = TRUE))
			gc_means <- with(dat_anova3, aggregate(y, by = list(GCM, RCP), mean, na.rm = TRUE))
			sgc_means <- with(dat_anova3, aggregate(y, by = list(Shift, GCM, RCP), mean, na.rm = TRUE))
			rsgc_means <- with(dat_anova3, aggregate(y, by = list(Region, Shift, GCM, RCP), mean, na.rm = TRUE))

			cell_var <- (nrow(cell_means) - 1) * var(cell_means$x, na.rm = TRUE)
			r_var <- (nrow(cell_means) - 1) / (nrow(r_means) - 1) * var(r_means$x)
			s_var <- (nrow(cell_means) - 1) / (nrow(s_means) - 1) * var(s_means$x)
			g_var <- (nrow(cell_means) - 1) / (nrow(g_means) - 1) * var(g_means$x)
			c_var <- (nrow(cell_means) - 1) / (nrow(c_means) - 1) * var(c_means$x)
			gc_var <- (nrow(cell_means) - 1) / (nrow(g_means) - 1) / (nrow(c_means) - 1) * var(gc_means$x)
			gc_var2 <- gc_var - g_var - c_var # separate variance of GCMxRCP-interaction from main effects
			sgc_var <- (nrow(cell_means) - 1) / (nrow(s_means) - 1) / (nrow(g_means) - 1) / (nrow(c_means) - 1) * var(sgc_means$x)
			sgc_var2 <- sgc_var - gc_var2 - s_var - g_var - c_var # separate variance of Shift * GCM * RCP interaction from main and lower-degree effects
			rsgc_var <- (nrow(cell_means) - 1) / (nrow(r_means) - 1) / (nrow(s_means) - 1) / (nrow(g_means) - 1) / (nrow(c_means) - 1) * var(rsgc_means$x)
			rsgc_var2 <- rsgc_var - sgc_var2 - gc_var2 - r_var - s_var - g_var - c_var
			resid_var <- cell_var - r_var - s_var - g_var - c_var - gc_var2 - sgc_var2
			
			vars6a <- c(cell_var, r_var, s_var, g_var, c_var, gc_var2, sgc_var2, rsgc_var2)
			vars6b <- c(cell_var, r_var, s_var, g_var, c_var, gc_var, sgc_var, rsgc_var)
		
			#extract sum of squares
			prop6a <- round(100 * as.numeric(vars6a) / sum(as.numeric(vars6a)), 1)
			names(prop6a) <- factors1
			#Residuals    Region     Shift      GCM      RCP    RCP:GCM Shift:RCP:GCM 
			#	 82.7     13.7      3.0      1.0      1.6     -1.5     -0.4 

			prop6b <- round(100 * as.numeric(vars6b) / sum(as.numeric(vars6b)), 1)
			names(prop6b) <- factors1
			#Residuals    Region     Shift      GCM      RCP    RCP:GCM Shift:RCP:GCM 
			#	 79.8     13.2      2.9      0.9      1.5      1.0      0.7 

			# variation influence of each region 
			var_by_region1 <- var_by_region2 <- matrix(NA, nrow = max(regions_n), ncol = 6, dimnames = list(label.regions, factors2))
			for (i in regions_n) {
				var_by_region1[i, "Region"] <- (nlevels(dat_anova3$Region) - 1 - 1) *
							var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region), mean, na.rm = TRUE))$x)

				var_by_region1[i, "Shift"] <- (nlevels(dat_anova3$Shift) - 1) * 
							var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Shift), mean, na.rm = TRUE))$x)

				var_by_region1[i, "Region x Shift"] <- (nlevels(dat_anova3$Region) - 1 - 1) * (nlevels(dat_anova3$Shift) - 1) * 
							var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region, Shift), mean, na.rm = TRUE))$x)

				var_by_region1[i, "Region x GCM x RCP"] <- (nlevels(dat_anova3$Region) - 1 - 1) * (nlevels(dat_anova3$GCM) - 1) * (nlevels(dat_anova3$RCP) - 1) * 
							var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region, GCM, RCP), mean, na.rm = TRUE))$x)

				var_by_region1[i, "Shift x GCM x RCP"] <- (nlevels(dat_anova3$Region) - 1 - 1) * (nlevels(dat_anova3$GCM) - 1) * (nlevels(dat_anova3$RCP) - 1) * 
							var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Shift, GCM, RCP), mean, na.rm = TRUE))$x)

				var_by_region1[i, "Region x Shift x GCM x RCP"] <- (nlevels(dat_anova3$Region) - 1 - 1) * (nlevels(dat_anova3$Shift) - 1) * (nlevels(dat_anova3$GCM) - 1) * (nlevels(dat_anova3$RCP) - 1) * 
							var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region, Shift, GCM, RCP), mean, na.rm = TRUE))$x)
			}
			prop6b <- round(100 * var_by_region1 / apply(var_by_region1, 1, sum, na.rm = T), 1)
			#            Region Shift Region x Shift Region x GCM x RCP Shift x GCM x RCP Region x Shift x GCM x RCP
			#South America       1.7  0.0      2.6        31.9        8.4            55.4
			#Southern Africa      NA  NA       NA         NA        NA             NA
			#Eastern Asia       1.4  0.3      2.3        29.7       11.3            55.0
			#Western & Central Asia  1.5  0.0      2.7        30.3        6.5            58.9
			#Western Mediterranean   0.6  0.1      2.3        22.8       11.7            62.4
			#North America       1.3  0.0      2.6        28.5        7.6            59.9

			for (i in regions_n) {
				var_by_region2[i, "Region"] <- var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region), mean, na.rm = TRUE))$x)

				var_by_region2[i, "Shift"] <- var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Shift), mean, na.rm = TRUE))$x)

				var_by_region2[i, "Region x Shift"] <- var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region, Shift), mean, na.rm = TRUE))$x)

				var_by_region2[i, "Region x GCM x RCP"] <- var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region, GCM, RCP), mean, na.rm = TRUE))$x)

				var_by_region2[i, "Shift x GCM x RCP"] <- var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Shift, GCM, RCP), mean, na.rm = TRUE))$x)

				var_by_region2[i, "Region x Shift x GCM x RCP"] <- var(with(dat_anova3[dat_anova3$Region != label.regions[i],], aggregate(y, by = list(Region, Shift, GCM, RCP), mean, na.rm = TRUE))$x)
			}
			prop6c <- round(100 * var_by_region2 / apply(var_by_region2, 1, sum, na.rm = T), 1)
			#            Region Shift Region x Shift Region x GCM x RCP Shift x GCM x RCP Region x Shift x GCM x RCP
			#South America      22.0  0.9      17.0        28.2        7.5            24.5
			#Southern Africa      NA  NA       NA         NA        NA             NA
			#Eastern Asia       18.6  7.4      14.9        25.6        9.7            23.7
			#Western & Central Asia  20.3  1.2      18.4        27.4        5.9            26.7
			#Western Mediterranean   9.8  4.5      17.7        23.6       12.1            32.3
			#North America      18.8  1.3      18.2        26.6        7.1            27.9
		}
		#---------------
		

		#---------------ALTERNATIVE7: additive elements of Whittaker 1984		
		if (do_attempt[[7]]) {
			#Whittaker, J. 1984. Model Interpretation from the Additive Elements of the Likelihood Function. Journal of the Royal Statistical Society. Series C (Applied Statistics) 33:52-64.

			#Whittaker 1984: sum of squares for additive elements
			temp <- whittaker_additive_elements(data = dat_anova3, circular = is_circular)
			probs <- probs7a <- temp$probs
			total <- total7a <- temp$total
			# Residuals        Primary_Region         Primary_Shift          Primary_GCM          Primary_RCP    Secondary_Region:Shift     Secondary_Region:GCM     Secondary_Region:RCP      Secondary_Shift:GCM      Secondary_Shift:RCP       Secondary_GCM:RCP   Tertiary_Region:Shift:GCM   Tertiary_Region:Shift:RCP    Tertiary_Region:GCM:RCP    Tertiary_Shift:GCM:RCP Quartery_Region:Shift:GCM:RCP 
			#	 77.7              8.0              0.5             12.5              0.7              0.0              0.1              0.1              0.6              0.1             -0.1             -0.2             -0.1              0.0              0.1              0.0 
		}	
		#---------------
		
		#---------------ALTERNATIVE8: adjusted R2 based on ideas in vegan::varpart and vegandocs("partitioning.pdf")
		if (do_attempt[[8]]) {
			#Compare adjusted R2 based on ideas in vegan::varpart and vegandocs("partitioning.pdf")
			#variation partitioning (and not variance partitioning; http://www.davidzeleny.net/anadat-r/doku.php/en:varpart)
			probs8a <- legendre_varpart(data = dat_anova3, circular = is_circular)
			#Residuals        Primary_Region         Primary_Shift          Primary_GCM          Primary_RCP    Secondary_Region:Shift     Secondary_Region:GCM     Secondary_Region:RCP      Secondary_Shift:GCM      Secondary_Shift:RCP       Secondary_GCM:RCP   Tertiary_Region:Shift:GCM   Tertiary_Region:Shift:RCP    Tertiary_Region:GCM:RCP    Tertiary_Shift:GCM:RCP Quartery_Region:Shift:GCM:RCP 
			#	 77.7              8.0              0.5             12.5              0.7              0.0              0.1              0.1              0.6              0.1             -0.1             -0.2             -0.1              0.0              0.1              0.0 
			# ==> result identical to probs7a
		}
		#---------------


		#---------------ALTERNATIVE9: variable importance based on model selection with AICc
		if (do_attempt[[9]]) {
			# variable importance based on model selection with AICc
			library(MuMIn)
			dat_anova4 <- dat_anova3[complete.cases(dat_anova3), ]
			m_global <- lm(y ~ Region + Shift + GCM + RCP + GCM:RCP + Shift:GCM:RCP + Region:Shift:GCM:RCP, data = dat_anova4, na.action = na.pass)
			m_subsets <- dredge(m_global)
			#  (Int) GCM RCP Rgn Shf GCM:RCP GCM:RCP:Shf GCM:RCP:Rgn:Shf df logLik  AICc  delta   weight
			#128 53.39 +  +  +  +  +    +      +        473 -1818617 3638181   0.00 1   
			#64 59.92 +  +  +  +  +    +              101 -1850134 3700471 62289.48 0   

			var_imp <- importance(m_subsets) #min = AICc(full)
			#delta(full, 2nd model) > 62289.48	 => all terms in full model have importance of 1

			m_global <- lm(y ~ Region*Shift*GCM*RCP, data = dat_anova4, na.action = na.pass)
			m_subsets <- dredge(m_global)
			#   (Int) GCM RCP Rgn Shf GCM:RCP GCM:Rgn GCM:Shf RCP:Rgn RCP:Shf Rgn:Shf GCM:RCP:Rgn GCM:RCP:Shf GCM:Rgn:Shf RCP:Rgn:Shf	GCM:RCP:Rgn:Shf df logLik  AICc  delta   weight
			#32768 53.39 +  +  +  +  +    +    +    +    +    +    +      +      +      +      	+        473 -1818617 3638181   0.00 1   
			#16384 43.61 +  +  +  +  +    +    +    +    +    +    +      +      +      +								361 -1819407 3639538  1356.38 0
			 
			prop8a <- importance(m_subsets) #min = AICc(full)
			#delta(full, 2nd model) > 1356.38	 => all terms in full model have importance of 1
		}
		#---------------



		#---------------COMPARE METHODS
		if (do_compare_methods) {
			prob_list <- list(prop5a, prop5b, prop5c, prop6b, probs7a, probs8a)
			names(prob_list) <- c()
	
			term_comb <- lapply(0:4, function(i) combn(c("Region", "Shift", "GCM", "RCP"), i))
			term_comb[[1]] <- matrix("Residuals", 1, 1)
			term_names <- unlist(sapply(term_comb, function(x) apply(x, 2, paste0, collapse = ":")))
	
			prob_agg <- matrix(NA, nrow = length(prob_list), ncol = sum(sapply(0:4, function(i) choose(4, i))), dimnames = list(names(prob_list), term_names))
	
			for (i in seq_along(prob_list)) {
				to_names <- names(prob_list[[i]])
				length_names <- sapply(strsplit(to_names, split = ":", fixed = TRUE), length)
				for (iv in seq_along(term_names)) {
					split_names <- strsplit(term_names[iv], split = ":", fixed = TRUE)
					length_term <- sapply(split_names, length)
					from_names <- split_names[[1]]
					temp <- sapply(from_names, function(w) grepl(w, to_names))
					iterm <- (length_names == length_term) & (if (dim(temp)[2] > 1) apply(temp, 1, all) else temp)
			
					if (sum(iterm) > 0) prob_agg[i, iv] <- prob_list[[i]][iterm]
				}
			}
			#   Residuals Region Shift GCM RCP Region:Shift Region:GCM Region:RCP Shift:GCM Shift:RCP GCM:RCP Region:Shift:GCM
			#[1,]   76.8  8.1  0.5 12.6 0.7      NA     NA     NA    NA    NA   1.4        NA
			#[2,]   62.2  8.1  NA 13.1 0.8      NA     NA     NA    NA    NA   1.4        NA
			#[3,]   62.7  8.1  0.5 12.5 0.7      NA     NA     NA    NA    NA   1.4        NA
			#[4,]   79.3  13.1  2.9 0.9 1.5      NA     NA     NA    NA    NA   1.0        NA
			#[5,]   77.7  8.0  0.5 12.5 0.7      0    0.1    0.1    0.6    0.1  -0.1       -0.2
			#[6,]   77.7  8.0  0.5 12.5 0.7      0    0.1    0.1    0.6    0.1  -0.1       -0.2
			#   Region:Shift:RCP Region:GCM:RCP Shift:GCM:RCP Region:Shift:GCM:RCP
			#[1,]        NA       NA      NA          NA
			#[2,]        NA       NA      2.0         12.5
			#[3,]        NA       NA      1.5         12.6
			#[4,]        NA       NA      0.7         0.6
			#[5,]       -0.1       0      0.1         0.0
			#[6,]       -0.1       0      0.1         0.0

			# ==> all attempts very similar, except Region:Shift:GCM:RCP and attempt6 moves variation from GCMs to regions
			# ==> use Whittaker 1984-based attempt7 because readily citable and easy to explain, but assumes additivity
		}
		#---------------
		
		
		#---------------PREPARE FINAL RESULT
		prop <- as.data.frame(matrix(NA, nrow = length(probs), ncol = 3))
		colnames(prop) <- c('factor', 'SS', 'prop')
		prop[, 'factor'] <- factors

		#extract sum of squares
		prop[, "SS"] <- probs * total

		#calculate proportion of variation explained
		prop[, "prop"] <- probs
		#---------------


		return(prop)
	}


	#Loop
	for (it in seq_along(typeList)) {
		for (ir in c(0, regions_n)) {
			fname <- file.path(dir.out_RV1, paste0(ftag_prop, "_", names(unlist(do_attempt))[unlist(do_attempt)], "_", typeList[it], "_", if (ir == 0) "All" else paste0(ir, gsub(" ", "", label.regions[ir])), "_v3.csv"))
			if (!file.exists(fname)) {
				res_prop <- as.data.frame(matrix(NA, nrow = length(factors), ncol = 1 + length(variables)))
				colnames(res_prop) <- c("factor", paste0("SSprop_", variables))
				res_prop[, 'factor'] <- factors

				for (il in seq_along(resList)) {
					temp_data <- get(resList[il])
					if (old) {
						i_subset <- if (ir == 0) rep(TRUE, nrow(temp_data$dLoc)) else temp_data$dLoc[, "Region"] != ir
						vars <- dimnames(temp_data$valCur)[[5]]
					} else {
						i_subset <- if (ir == 0) rep(TRUE, nrow(dLoc)) else dLoc[, "Region"] != ir
						vars <- dimnames(temp_data)[[5]]
						ivar <- sapply(variables, function(x) grep(x, vars)[1])
						vars <- vars[ifelse(is.na(ivar), 0, ivar)]
					}
					

					for (iv in seq_along(vars)) {
						print(paste(Sys.time(), typeList[it], if (ir == 0) "All" else label.regions[ir], resList[il], vars[iv]))
						temp <- do_varpart_regional_response(type = typeList[it], res_data = temp_data, varname = vars[iv], i_subset = i_subset)

						icol <- grepl(paste0("_", variables[sapply(variables, function(x) any(grepl(x, vars[iv])))]), colnames(res_prop))						
						res_prop[, icol] <- temp[, "prop"]
					}
				}

				write.csv(res_prop, file = fname)
			}
		}
	}
}


#---aggregate the variation partitioning (separately for climate inputs and response variables)
if (do_aggregation) {
	if (old) {
		var_groups <- list(climate = c("MAP_mm", "MAT_C",
									"UNAridityIndex_Normals_none",
									"Seasonality_monthlyTandPPT_PearsonCor", "PET_mm"),
							response = c("ThermalSnowfreeDryPeriods_SWPcrit3000kPa_topLayers_DrySpellsAllLayers_maxDuration_days","ThermalSnowfreeDryPeriods_SWPcrit3000kPa_bottomLayers_DrySpellsAllLayers_maxDuration_days",
										"ThermalSnowfreeWetPeriods_SWPcrit1500kPa_topLayers_AvailableWater_mm", "ThermalSnowfreeWetPeriods_SWPcrit1500kPa_bottomLayers_AvailableWater_mm",
										"WetSoilPeriods_SWPcrit1500kPa_NSadj_topLayers_AllLayersWet_Duration_Total_days_mean", 
										"TeeriEtAl1976_NSadj_FreezeFreeGrowingPeriod_days_mean",
										"TranspirationBottomToTranspirationTotal_fraction_mean", 
										"TtoAET", "AET_mm"))
		var_labels_groups <- list(climate = c("MAP (mm)", "MAT (C)",
									"Aridity index (-)",
									"Seasonality (-)", "PET (mm)"),
							response = c("DDGP0 (days)","DDGP20 (days)",
										"AWGP0 (mm x days)", "AWGP20 (mm x days)",
										"WD0 (days)",
										"Growing period (days)",
										"T[deep]/T[total] (-)", 
										"T/AET (-)", "AET (mm)"))
	} else {
		var_groups <- lapply(resList[1:2], function(x) dimnames(get(x))[[5]])
		names(var_groups) <- gsub("res", "", gsub("2", "", resList[1:2]))
		var_groups <- lapply(var_groups, function(x) variables[sapply(variables, function(v) any(sapply(x, function(x2) grepl(v, x2))))])
		
		var_labels_groups <- list(label_climate, label_response_sel)
		names(var_labels_groups) <- gsub("res", "", gsub("2", "", resList[1:2]))
	}
	
	fname_vp_tables <- list.files(file.path(dir.out_RV1), pattern = ftag_prop)
	
	for (it in seq_along(typeList)) {
		for (ivg in seq_along(var_groups)) {
			#varpart1, overall; varpart2, leave-one-out-region
			varpart1 <- as.data.frame(matrix(NA, nrow = length(factors), ncol = 1 + length(var_groups[[ivg]])))
			colnames(varpart1) <- c("factor", var_groups[[ivg]])
			varpart1[, "factor"] <- factors
			varpart2 <- array(NA, dim = c(length(factors), length(var_groups[[ivg]]), length(regions_N)), dimnames = list(NULL, var_groups[[ivg]], label.regions)) 

			for (iv in seq_along(var_groups[[ivg]])) {
				#variable <- variables[grep(var_groups[[ivg]][iv], variables)[1]]
				variable <- variables[!is.na(sapply(variables, function(x) grep(x, var_groups[[ivg]][iv])[1]))]
				if (!is.na(variable)) {
					res.temp <- get(resList[grepl(gsub("[[:digit:]]", "", names(variable)), resList)])
				
					temp <- read.csv(file = file.path(dir.out_RV1, fname_vp_tables[grepl(paste0("_", typeList[it], "_"), fname_vp_tables) & grepl("_All_", fname_vp_tables)]))
#TODO: why do have instances of same variable different values among resList? e.g., SSprop_MAT_C vs. SSprop_MAT_C_mean
					varpart1[, 1 + iv] <- temp[, grep(variable, colnames(temp))[1]]
				
					for (ir in regions_n) {
						temp <- read.csv(file = file.path(dir.out_RV1, fname_vp_tables[grepl(paste0("_", typeList[it], "_"), fname_vp_tables) & grepl(paste0(ir, gsub(" ", "", label.regions[ir])), fname_vp_tables)]))
						varpart2[, iv, ir] <- temp[, grep(variable, colnames(temp))[1]]
					}
				} else {
					warning(paste("Requested variable", var_groups[[ivg]][iv], "is not available"))
				}
			}

		
			# Aggregation across variables (and regions)
			overall_mean <- apply(varpart1[, -1], 1, mean, na.rm = TRUE)	# mean among variables for each term
			overall_sd <- apply(varpart1[, -1], 1, sd, na.rm = TRUE)		# sd among variables for each term
			overall_var <- apply(varpart1[, -1], 1, var, na.rm = TRUE)	# variance among variables for each term
		
			region_means <- apply(varpart2, c(1, 3), mean, na.rm = TRUE)	# mean among variables for each term and left-out region
			region_vars <- apply(varpart2, c(1, 3), var, na.rm = TRUE)	# variance among variables for each term and left-out region
	#		grand_mean <- apply(region_means, 1, mean, na.rm = TRUE)		# mean among regions of means among variables for each term
	#		grand_var <- apply(region_means, 1, var, na.rm = TRUE)		# variance among regions of means among variables for each term
		
	#		region_diff1 <- region_means - overall_mean
	#		region_diff2 <- region_means - grand_mean
	#		region_meanbias1 <- apply(abs(region_diff1), 2, sum)
	#		region_wmeanbias1 <- apply(abs(region_diff1), 2, weighted.mean, w = abs(overall_mean), na.rm = TRUE)
	#		region_meanbias2 <- apply(abs(region_diff2), 2, sum)
	#		region_wmeanbias2 <- apply(abs(region_diff2), 2, weighted.mean, w = abs(grand_mean), na.rm = TRUE)
		
			region_varratios1 <- region_vars / overall_var
	#		region_meanvarratio1 <- apply(region_varratios1, 2, mean, na.rm = TRUE)
			region_wmeanvarratio11 <- apply(region_varratios1, 2, weighted.mean, w = abs(overall_mean), na.rm = TRUE)
	#		region_wmeanvarratio12 <- apply(region_varratios1, 2, weighted.mean, w = abs(grand_mean), na.rm = TRUE)

			# Final results
			write.csv(varpart1, file = file.path(dir.out_RV2, paste0("Table_VariationPartitioning_Variables_", names(var_groups)[ivg], "_", typeList[it], ".csv")))
			temp <- matrix(c(overall_mean, overall_sd), ncol = 2, byrow = FALSE, dimnames = list(factors, c("mean", "sd")))
			write.csv(temp, file = file.path(dir.out_RV2, paste0("Table_VariationPartitioning_Means_", names(var_groups)[ivg], "_", typeList[it], ".csv")))
			write.csv(region_wmeanvarratio11, file = file.path(dir.out_RV2, paste0("Table_VariationPartitioning_RelativeRegionVariances_", names(var_groups)[ivg], "_", typeList[it], ".csv")))
		
			# Figures
	#		temp <- barplot(overall_mean, ylim = c(0, 100))
	#		arrows(x0 = temp, y0 = overall_mean - overall_sd, y1 = overall_mean + overall_sd, code = 3, angle = 90, length = 0.25 * par("cin")[1])
		
			pdf(file = file.path(dir.out_RV3, paste0("Fig_VariationPartitioning_", names(var_groups)[ivg], "_", typeList[it], "_boxplot.pdf")))
			op <- par(mar = c(10, 4, 0.1, 0.1))
				temp <- boxplot(t(varpart1[, -1]), names = factors, las = 3, ylim = c(0, 100), ylab = "Percentage of total variation")
				for (i in seq_along(temp$out)[1:4]) {
					itvar <- which.min(abs(temp$out[i] - varpart1[temp$group[i], -1]))
					text(x = temp$group[i], y = temp$out[i], labels = itvar, adj = c(-1, 0))
				}
			par(op)
			dev.off()
		
		
			pdf(file = file.path(dir.out_RV3, paste0("Fig_VariationPartitioning_", names(var_groups)[ivg], "_", typeList[it], "_values.pdf")))
			op <- par(mar = c(10, 3, 0.1, 0.1), mgp = c(2, 1, 0))
				matplot(sapply(seq_along(var_groups[[ivg]]), function(i) jitter(seq_along(factors))), varpart1[, -1], pch = seq_along(var_groups[[ivg]]), col = rep_len(1:6, length(var_groups[[ivg]])), ylim = c(0, 100), xlab = "", ylab = "Percentage of total variation", axes = FALSE)
				axis(side = 1, at = seq_along(factors), labels = FALSE)
				axis(side = 2)
				mtext(text = factors, side = 1, line = 1, at = seq_along(factors), las = 3, adj = 1)
				legend("topright", ncol = 2, legend = var_labels_groups[[ivg]], pch = seq_along(var_groups[[ivg]]), col = rep_len(1:6, length(var_groups[[ivg]])), cex = 1, bty = "n", inset = 0.05)
			par(op)
			dev.off()
		}
		
	}
	
}



